<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title> JavaScript Start-up Performance · Learn and Share</title><meta name="description" content="JavaScript Start-up Performance - Hung Tan Nguyen"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="theme-color" content="#FB4D42"><meta name="google-site-verification" content="rk-Nc1c8xi1CdZ0ZQIVV-ifsndGrHanIuSHI-yTHZYE"><link rel="short icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="/css/zoom.css"><meta property="og:title" content="JavaScript Start-up Performance"><meta property="og:image" content="https://cdn-images-1.medium.com/max/2000/1*ZpwZLFDNYZodJDerr7-37A.png"><meta property="og:description" content="JavaScript Start-up PerformanceAs web developers, we know how easy it is to end up with web page bloat. But loading a webpage is much more than shipping bytes down the wire. Once the browser has downloaded our page’s scripts it then has to parse, interpret &amp;amp; run them. In this post, we’ll dive into this phase for JavaScript, why it might be slowing down your app’s start-up &amp;amp; how you can fix it.
Historically, we just haven’t spent a lot of time optimizing for the JavaScript Parse/Compile step. We almost expect scripts to be immediately parsed and executed as soon as the parser hits a &amp;lt;script&amp;gt; tag. But this isn’t quite the case. Here’s a simplified breakdown of how V8 works:
A simplified view of how V8 works. This is our idealized pipeline that we’re working towards.
Let’s focus on some of the main phases."></head><body><div class="wrap"><div class="header"><a href="/" class="logo-link"><img src="/favicon.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/nthung2112" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/about" target="_self" class="nav-list-link">ABOUT</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li><li class="nav-list-item search-form-input"><div class="search-icon"><div class="search-icon__circle"></div><div class="search-icon__rectangle"></div></div></li></ul><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" placeholder="Type something..." class="ins-search-input"><span class="ins-close ins-selectable"><div class="close-icon"><div class="close-icon__x"></div><div class="close-icon__y"></div></div></span></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div><script>var rootUrl = "/";
var contentUrl = '/content.json';
(function (window) {
  var INSIGHT_CONFIG = {
  TRANSLATION: {
      POSTS:'Posts',
      PAGES: 'Pages',
      CATEGORIES: 'Categories',
      TAGS: 'Tags',
      UNTITLED: '(Untitled)'
    },
    ROOT_URL: rootUrl,
    CONTENT_URL: contentUrl,
  };
  window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);</script></div></div><section class="container"><div class="post"><article class="post-block"><div class="wrap"><h1 class="post-title">JavaScript Start-up Performance</h1><h2 class="post-subtitle"></h2><header class="post-info">Dec 16, 2017<div class="tags"><a href="/tags/javascript" class="tag-link">#javascript</a></div><div class="fb-ir-time"><time dateTime="2017-12-16T07:46:39.000Z" class="op-modified"></time><time dateTime="2017-12-16T07:46:39.000Z" class="op-published"></time></div></header></div><div class="post-banner"><img src="https://cdn-images-1.medium.com/max/2000/1*ZpwZLFDNYZodJDerr7-37A.png"></div><div class="wrap"><div class="post-content"><h1 id="JavaScript-Start-up-Performance"><a href="#JavaScript-Start-up-Performance" class="headerlink" title="JavaScript Start-up Performance"></a>JavaScript Start-up Performance</h1><p>As web developers, we know how easy it is to end up with web page bloat. But <strong>loading</strong> a webpage is much more than shipping bytes down the wire. Once the browser has downloaded our page’s scripts it then has to parse, interpret &amp; run them. In this post, we’ll dive into this phase for JavaScript, <em>why</em> it might be slowing down your app’s start-up &amp; <em>how</em> you can fix it.</p>
<p>Historically, we just haven’t spent a lot of time optimizing for the JavaScript Parse/Compile step. We almost expect scripts to be immediately parsed and executed as soon as the parser hits a <code>&lt;script&gt;</code> tag. But this isn’t quite the case. <strong>Here’s a simplified breakdown of how V8 works</strong>:</p>
<p><img src="https://cdn-images-1.medium.com/max/2000/1*GuWInZljjvtDpdeT6O0emA.png" alt="">A simplified view of how V8 works. This is our idealized pipeline that we’re working towards.</p>
<p>Let’s focus on some of the main phases.<br><a id="more"></a></p>
<h4 id="What-slows-our-web-apps-from-booting-up"><a href="#What-slows-our-web-apps-from-booting-up" class="headerlink" title="What slows our web apps from booting up?"></a><strong>What slows our web apps from booting up?</strong></h4><p>Parsing, Compiling and Executing scripts are things a JavaScript engine spends <strong>significant</strong> time in during start-up. This matters as if it takes a while, it can <strong>delay</strong> how soon users can <strong>interact</strong> with our site. Imagine if they can see a button but not click or touch it for multiple seconds. This can <strong>degrade</strong> the user experience.</p>
<p><img src="https://cdn-images-1.medium.com/max/2000/0*M94-AavlZjGoudZG." alt="">Parse &amp; Compile times for a popular website using V8’s Runtime Call Stats in Chrome Canary. Notice how a slow Parse/Compile on desktop can take far longer on average mobile phones.</p>
<p>Start-up times matter for <strong>performance-sensitive</strong> code. In fact, V8 - Chrome’s JavaScript engine, spends a <strong>large</strong> amount of time parsing and compiling scripts on top sites like Facebook, Wikipedia and Reddit:</p>
<p><img src="https://cdn-images-1.medium.com/max/2000/1*XjHkzz0B7KlcDbLFD1JS8Q.png" alt="">The pink area (JavaScript) represents time spent in V8 and Blink’s C++, while the orange and yellow represent parse and compile.</p>
<p>Parse and Compile have also been highlighted as a bottleneck by a <strong>number</strong> of large sites &amp; frameworks you may be using. Below are tweets from Facebook’s Sebastian Markbage and Google’s Rob Wormald:</p>
<script src="//gist.github.com/https://medium.com/media/bfe5fc0258489a112c44c78f4de550d9?postId=69200f43b201.js"></script><script src="//gist.github.com/https://medium.com/media/553bef66abd9082b744501ac06ca6cc5?postId=69200f43b201.js"></script><img src="https://cdn-images-1.medium.com/max/1200/1*nkJwMuE5PpgF_pE0e6RM6g.jpeg" alt="">Sam Saccone calls out the cost of JS parse in ‘<a href="https://www.youtube.com/watch?v=RWLzUnESylc" target="_blank" rel="noopener">Planning for Performance</a>’<br><br>As we move to an increasingly mobile world, it’s important that we understand the <strong>time spent in Parse/Compile can often be 2–5x as long on phones as on desktop</strong>. Higher-end phones (e.g the iPhone or Pixel) will perform very differently to a Moto G4. This highlights the importance of us testing on representative hardware (not just high-end!) so our users’ experiences don’t suffer.<br><br><img src="https://cdn-images-1.medium.com/max/1600/1*dnhO1M_zlmAhvtQY_7tZmA.jpeg" alt=""><a href="https://docs.google.com/spreadsheets/d/1wHcNNQea28LhwQ_amFamT33d5woVrJfJy53Z1k6V090/edit?usp=sharing" target="_blank" rel="noopener">Parse times</a> for a 1MB bundle of JavaScript across desktop &amp; mobile devices of differing classes. Notice how close a high-end phone like an iPhone 7 is to perf on a Macbook Pro vs the performance as we go down the graph towards average mobile hardware.<br><br>If we’re shipping huge bundles for our app, this is where endorsing modern bundling techniques likecode-splitting, tree-shaking and Service Worker caching can really make a huge difference. That said, <strong>even a small bundle, written poorly or with poor library choices can result in the main thread being pegged for a long time in compilation or function call times.</strong> It’s important to holistically measure and understand where our real bottlenecks are.<br><br>### What Are JavaScript Parse &amp; Compile bottlenecks for the average website?<br><br>“Buuuut, I’m not Facebook”, I hear you say dear, reader. <strong>“How heavy are Parse &amp; Compile times for average sites out in the wild?”</strong>, you might be asking. Let’s science this out!<br><br>I spent two months <a href="https://github.com/GoogleChrome/discovery/issues/1" target="_blank" rel="noopener">digging into</a> the performance of a large set of production sites (6000+) built with different libraries and frameworks — like React, Angular, Ember and Vue. Most of the tests were recently redone on WebPageTest so you can easily redo them yourself or dig into the numbers if you wish. Here are some insights.<br><br><strong>Apps became interactive in 8 seconds on desktop (using cable) and 16 seconds on mobile (Moto G4 over 3G)</strong><br><br><img src="https://cdn-images-1.medium.com/max/2000/1*WC4zanI0DKAoSiJVU3VUeA.png" alt=""><br><br><strong>What contributed to this? Most apps spent an average of 4 seconds in start-up (Parse/Compile/Exec)..on desktop.</strong><br><br><img src="https://cdn-images-1.medium.com/max/1600/1*NacL9cZJ1osZowPS6hbCsQ.jpeg" alt=""><br><br>On mobile, parse times were up to 36% higher than they were on desktop.<br><br><img src="https://cdn-images-1.medium.com/max/2000/1*uTRfB5pne06h8lp5jGtiIQ.jpeg" alt=""><br><br><strong>Was everyone shipping huge JS bundles? Not as large as I had guessed, but there’s room for improvement.</strong> At the median, developers shipped 410KB of gzipped JS for their pages. This is in line with the 420KB over ‘average JS per page’ reported by the HTTPArchive. The worst offenders were sending anywhere up to 10MB of script down the wire. Oof.<br><br><img src="https://cdn-images-1.medium.com/max/1600/1*GvwfE2GjKQyLBKPmmfRwuA.png" alt=""><a href="http://httparchive.org/trends.php?s=All&amp;minlabel=Nov+15+2015&amp;maxlabel=Nov+15+2016#bytesJS&amp;reqJS" target="_blank" rel="noopener">HTTPArchive stat</a>: the average page ships down 420KB of JavaScript<br><br><strong>Script size is important, but it isn’t everything. Parse and Compile times don’t necessarily increase linearly when the script size increases.</strong> Smaller JavaScript bundles generally do result in a faster <strong>load</strong> time (regardless of our browser, device &amp; network connection) but 200KB of our JS !== 200KB of someone else’s and can have wildly different parse and compile numbers.<br><br>### <strong>Measuring JavaScript Parse &amp; Compile today</strong><br><br><strong>Chrome DevTools</strong><br><br>Timeline (Performance panel) &gt; Bottom-Up/Call Tree/Event Log will let us drill into the amount of time spent in Parse/Compile. For a more complete picture (like the time spent in Parsing, Preparsing or Lazy Compiling), we can turn on <strong>V8’s Runtime Call Stats</strong>. In Canary, this will be in Experiments &gt; V8 Runtime Call Stats on Timeline.<br><br><img src="https://cdn-images-1.medium.com/max/2000/0*rWkYJzc6Cp0r3Xkr." alt=""><br><br><strong>Chrome Tracing</strong><br><br><strong>about:tracing</strong> — Chrome’s lower-level Tracing tool allows us to use the <code>disabled-by-default-v8.runtime_stats</code> category to get deeper insights into where V8 spends its time. V8 have a <a href="https://docs.google.com/presentation/d/1Lq2DD28CGa7bxawVH_2OcmyiTiBn74dvC6vn2essroY/edit#slide=id.g1a504e63c9_2_84" target="_blank" rel="noopener">step-by-step guide</a> on how to use this that was published just the other day.<br><br><img src="https://cdn-images-1.medium.com/max/1600/0*P-_pLIITtYJRikRN." alt=""><br><br><strong>WebPageTest</strong><br><br><img src="https://cdn-images-1.medium.com/max/1200/1*y6x_vr7aOxK4jHG9blgseg.png" alt=""><br><br>WebPageTest’s “Processing Breakdown” page includes insights into V8 Compile, EvaluateScript and FunctionCall time when we do a trace with the Chrome &gt; Capture Dev Tools Timeline enabled.<br><br>We can now also get out the <strong>Runtime Call Stats</strong> by specifying <code>disabled-by-default-v8.runtime_stats</code> as a custom Trace category (Pat Meenan of WPT now does this by default!).<br><br><img src="https://cdn-images-1.medium.com/max/1600/1*tV48evC-XzYkoHonyKGkOw.png" alt=""><br><br>For a guide on how to get the most out of this, see <a href="https://gist.github.com/addyosmani/45b135900a7e3296e22673148ae5165b" target="_blank" rel="noopener">this gist</a> I wrote up.<br><br><strong>User Timing</strong><br><br>It’s possible to measure Parse times through the <a href="https://w3c.github.io/user-timing/#dom-performance-mark" target="_blank" rel="noopener">User Timing API</a> as Nolan Lawson points out below:<br><br><script src="//gist.github.com/https://medium.com/media/3a4c46356a6de348271a00bff1d4d2d4?postId=69200f43b201.js"></script>
<p>The third <code>&lt;script&gt;</code> here isn’t important, but it’s the first <code>&lt;script&gt;</code> being separate from the second (<em>performance.mark()</em> starting before the <code>&lt;script&gt;</code> has been reached) that is.</p>
<p><em>This approach can be affected on subsequent reloads by V8’s preparser. This could be worked around by appending a random string to the end of the script, something Nolan does in his optimize-js benchmarks.</em></p>
<p>I use a similar approach for measuring the impact of JavaScript Parse times using Google Analytics:</p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*ziA8f9KhB1gOt-Mq07cRFw.jpeg" alt="">A custom Google Analytics dimension for ‘parse’ allows me to measure JavaScript parse times from real users and devices hitting my pages in the wild.</p>
<p><strong>DeviceTiming</strong></p>
<p>Etsy’s <a href="https://github.com/danielmendel/DeviceTiming" target="_blank" rel="noopener">DeviceTiming</a> tool can help measure parse &amp; execution times for scripts in a controlled environment. It works by wrapping local scripts with instrumentation code so that each time our pages are hit from different devices (e.g laptops, phones, tablets) we can locally compare parse/exec. Daniel Espeset’s <a href="http://talks.desp.in/unpacking-the-black-box" target="_blank" rel="noopener">Benchmarking JS Parsing and Execution on Mobile Devices</a> goes into more detail on this tool.</p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*FFzrH2QUiQZFX2rlF5e2-g.jpeg" alt=""></p>
<h3 id="What-can-we-do-to-lower-our-JavaScript-parse-times-today"><a href="#What-can-we-do-to-lower-our-JavaScript-parse-times-today" class="headerlink" title="What can we do to lower our JavaScript parse times today?"></a><strong>What can we do to lower our JavaScript parse times today?</strong></h3><ul>
<li><strong>Ship less JavaScript</strong>. The less script that requires parsing, the lower our overall time spent in the parse &amp; compile phases will be.</li>
<li><strong>Use code-splitting to only ship the code a user needs for a route and lazy load the rest</strong>. This probably is going to help the most to avoid parsing too much JS. Patterns like <a href="https://developers.google.com/web/fundamentals/performance/prpl-pattern/" target="_blank" rel="noopener">PRPL</a> encourage this type of route-based chunking, now used by Flipkart, Housing.com and Twitter.</li>
<li><strong>Script streaming:</strong> In the past, V8 have told developers to use <code>async/defer</code> to opt into <a href="https://blog.chromium.org/2015/03/new-javascript-techniques-for-rapid.html" target="_blank" rel="noopener">script streaming</a> for parse-time improvements of between 10–20%. This allows the HTML parser to at least detect the resource early, push the work to the script streaming thread and not halt the document parsing. Now that this is done for parser-blocking scripts too, I don’t think there’s anything actionable we need to do here. V8 recommend <strong>loading larger bundles earlier on as there’s only one streamer thread</strong> (more on this later)</li>
<li><strong>Measure the parse cost of our dependencies</strong>, such as libraries and frameworks. Where possible, switch them out for dependencies with faster parse times (e.g switch React for Preact or Inferno, which require fewer bytes to bootup and have smaller parse/compile times). Paul Lewis covered <a href="https://aerotwist.com/blog/when-everything-is-important-nothing-is/" target="_blank" rel="noopener">framework bootup</a> costs in a recent article. As Sebastian Markbage has also <a href="https://twitter.com/sebmarkbage/status/829733454119989248" target="_blank" rel="noopener">noted</a>, <strong>a good way to measure start-up costs for frameworks is to first render a view, delete and then render again as this can tell you how it scales.</strong> The first render tends to warm up a bunch of lazily compiled code, which a larger tree can benefit from when it scales.</li>
</ul>
<p>If our JavaScript framework of choice supports an ahead-of-time compilation mode (AoT), this can also help heavily reduce the time spent in parse/compile. Angular apps benefit from this for example:</p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*sr4eb-cx3lq7hVrJGfDNaw.png" alt="">Nolan Lawson’s ‘<a href="https://channel9.msdn.com/Blogs/msedgedev/nolanlaw-web-perf-crisis" target="_blank" rel="noopener">Solving the Web Performance Crisis</a>’</p>
<h3 id="What-are-browsers-doing-to-improve-Parse-amp-Compile-times-today"><a href="#What-are-browsers-doing-to-improve-Parse-amp-Compile-times-today" class="headerlink" title="What are browsers doing to improve Parse &amp; Compile times today?"></a><strong>What are <em>browsers</em> doing to improve Parse &amp; Compile times today?</strong></h3><p>Developers are not the only ones to still be catching up on real-world start-up times being an area for improvement. V8 discovered that Octane, one of our more historical benchmarks, was a poor proxy for real-world performance on the 25 popular sites we usually test. Octane can be a poor proxy for 1) <strong>JavaScript frameworks</strong> (typically code that isn’t mono/polymorphic) and 2) <strong>real-page app startup</strong> (where most code is cold). These two use-cases are pretty important for the web. That said, Octane isn’t unreasonable for all kinds of workloads.</p>
<p>The V8 team has been hard at work improving start-up time and we’ve already seem some wins here:</p>
<script src="//gist.github.com/https://medium.com/media/f34895d2d5798e73d1987965288e5a55?postId=69200f43b201.js"></script>
<p>We also estimate a 25% improve on V8 parse times for many pages looking at our Octane-Codeload numbers:</p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*cE8uvuvb0-iZslygh2NCTQ.jpeg" alt=""></p>
<p>And we’re seeing wins in this area for Pinterest too. There are a number of other explorations V8 has started over the last few years to improve Parsing and Compile times.</p>
<p><strong>Code caching</strong></p>
<p><img src="https://cdn-images-1.medium.com/max/1200/1*xChjWSbT1rCqgLMacOMotQ.png" alt="">From <a href="https://www.nativescript.org/blog/using-v8-code-caching-to-minimize-app-load-time-on-android" target="_blank" rel="noopener">using V8’s code caching</a></p>
<p>Chrome 42 introduced <a href="http://v8project.blogspot.com/2015/07/code-caching.html" target="_blank" rel="noopener">code caching </a>— a way to store a local copy of compiled code so that when users returned to the page, steps like script fetching, parsing and compilation could all be skipped. At the time we noted that this change allowed Chrome to avoid about 40% of compilation time on future visits, but I want to provide a little more insight into this feature:</p>
<ul>
<li>Code caching triggers for scripts that are executed <strong>twice in 72 hours</strong>.</li>
<li>For scripts of Service Worker: Code caching triggers for scripts that are executed twice in 72 hours.</li>
<li>For scripts stored in Cache Storage via Service Worker: Code caching triggers for scripts in the <strong>first execution</strong>.</li>
</ul>
<p>So, yes. <strong>If our code is subject to caching V8 will skip parsing and compiling on the third load.</strong></p>
<p>We can play around with these in <em>chrome://flags/#v8-cache-strategies-for-cache-storage</em> to look at the difference. We can also run Chrome with — js-flags=profile-deserialization to see if items are being loaded from the code cache (these are presented as deserialization events in the log).</p>
<p>One caveat with code caching is that it only caches what’s being eagerly compiled. This is generally only the top-level code that’s run once to setup global values. Function definitions are usually lazily compiled and aren’t always cached. <strong>IIFEs</strong> (for users of optimize-js ;)) are also included in the V8 code cache as they are also eagerly compiled.</p>
<p><strong>Script Streaming</strong></p>
<p><a href="https://blog.chromium.org/2015/03/new-javascript-techniques-for-rapid.html" target="_blank" rel="noopener">Script streaming</a> allows async or defer scripts to be parsed on a <strong>separate background thread</strong> once downloading begins and improves page loading times by up to 10%. As noted earlier, this now also works for <strong>sync</strong> scripts.</p>
<p><img src="https://cdn-images-1.medium.com/max/2000/1*ooXJ0NES-gXEzteaGPL2nQ.png" alt=""></p>
<p>Since the feature was first introduced, V8 have switched over to allowing <strong>all scripts</strong>, <em>even</em> parser blocking <code>&lt;script src=””&gt;</code> to be parsed on a background thread so everyone should be seeing some wins here. The only caveat is that there’s only one streaming background thread and so it makes sense to put our large/critical scripts in here first. <em>It’s important to measure for any potential wins here.</em></p>
<p><strong>Practically, <code>&lt;script defer&gt;</code> in the <code>&lt;head&gt;</code> so we can discover the resource early and then parse it on the background thread.</strong></p>
<p>It’s also possible to check with DevTools Timeline whether the correct scripts get streamed — if there’s one big script that dominates the parse time, it would make sense to make sure it’s (usually) picked up by the streaming.</p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*FAvUG7DrVJUXCK3oweMSLQ.png" alt=""></p>
<p><strong>Better Parsing &amp; Compiling</strong></p>
<p>Work is ongoing for a slimmer and faster Parser that frees up memory and is more efficient with data structures. Today, the <strong>largest</strong> cause of main thread jank for V8 is the nonlinear parsing cost. Take a snippet of UMD:</p>
<p>(function (global, <strong>module</strong>) { … })(this, function <strong>module</strong>() { <em>my functions</em> })</p>
<p>V8 won’t know that <strong>module</strong> is definitely needed so we won’t compile it when the main script gets compiled. When we decide to compile <strong>module</strong>, we need to reparse all of the inner functions. This is what makes V8’s parse-times non-linear. Every function at n-th depth is parsed n times and causes jank.</p>
<p>V8 are already working on collecting info about inner functions during the initial compile, so any future compilations can <em>ignore</em> their inner functions. For <strong>module</strong>-style functions, this should result in a large perf improvement.</p>
<p>See ‘<a href="https://docs.google.com/presentation/d/1214p4CFjsF-NY4z9in0GEcJtjbyVQgU0A-UqEvovzCs/edit#slide=id.p" target="_blank" rel="noopener">The V8 Parser(s) — Design, Challenges, and Parsing JavaScript Better</a>’ for the full story.</p>
<p>V8 are also exploring offloading parts of JavaScript compilation to the <strong>background</strong> during startup.</p>
<p><strong>Precompiling JavaScript?</strong></p>
<p>Every few years, it’s proposed engines offer a way to <em>precompile</em> scripts so we don’t waste time parsing or compiling code pops up. The idea is if instead, a build-time or server-side tool can just generate bytecode, we’d see a large win on start-up time. My opinion is shipping bytecode can increase your load-time (it’s larger) and you would likely need to sign the code and process it for security. V8’s position is for now we think exploring avoiding reparsing internally will help see a decent enough boost that precompilation may not offer too much more, but are always open to discussing ideas that can lead to faster startup times. That said, V8 are exploring being more aggressive at compiling and code-caching scripts when you update a site in a Service Worker and we hope to see some wins with this work.</p>
<p>We discussed precompilation at BlinkOn 7 with Facebook and Akamai and my notes can be found <a href="https://gist.github.com/addyosmani/4009ee1238c4b1ff6f2a2d8a5057c181" target="_blank" rel="noopener">here</a>.</p>
<p><strong>The Optimize JS lazy-parsing parens ‘hack’</strong></p>
<p>JavaScript engines like V8 have a lazy parsing heuristic where they pre-parse most of the functions in our scripts before doing a complete round of parsing (e.g to check for syntax errors). This is based on the idea that most pages have JS functions that are lazily executed if at all.</p>
<p><img src="https://cdn-images-1.medium.com/max/1200/1*LMRg_jHJeP53vdy8aiTEJQ.png" alt=""></p>
<p>Pre-parsing can speed up startup times by only checking the minimal a browser needs to know about functions. This breaks down with IIFEs. Although engines try to skip pre-parsing for them, the heuristics aren’t always reliable and this is where tools like <a href="https://github.com/nolanlawson/optimize-js" target="_blank" rel="noopener">optimize-js</a> can be useful.</p>
<p>optimize-js parses our scripts in advance, inserts parenthesis where it knows (or assumes via heuristics) functions will be immediately executed enabling <strong>faster execution</strong>. Some of the paren-hacked functions are sure bets (e.g IIFEs with !). Others are based on heuristics (e.g in a Browserify or Webpack bundle it’s assumed all modules are eagerly loaded which isn’t necessarily the case). Eventually, V8 hopes for such hacks to not be required but for now this is an optimization we can consider if we know what you’re doing.</p>
<p><em>V8 are also working on reducing the cost for cases where we guess wrong, and that should also reduce the need for the parens hack</em></p>
<h3 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h3><p><strong>Start-up performance matters.</strong> Acombination of slow parse, compile and execution times can be a real bottleneck for pages that wish to boot-up quickly. <strong>Measure</strong> how long your pages spend in this phase. Discover what you can do to make it faster.</p>
<p>We’ll keep working on improving V8 start-up performance from our end as much as we can. We promise ;) Happy perfing!</p>
<h3 id="Read-More"><a href="#Read-More" class="headerlink" title="Read More"></a><strong>Read More</strong></h3><ul>
<li><a href="https://www.youtube.com/watch?v=RWLzUnESylc" target="_blank" rel="noopener">Planning for Performance</a></li>
<li><a href="https://twitter.com/MSEdgeDev/status/819985530775404544" target="_blank" rel="noopener">Solving the Web Performance Crisis by Nolan Lawson</a></li>
<li><a href="https://timkadlec.com/2014/09/js-parse-and-execution-time/" target="_blank" rel="noopener">JS Parse and Execution Time</a></li>
<li><a href="http://carlos.bueno.org/2010/02/measuring-javascript-parse-and-load.html" target="_blank" rel="noopener">Measuring Javascript Parse and Load</a></li>
<li><a href="https://www.safaribooksonline.com/library/view/velocity-conference-new/9781491900406/part78.html" target="_blank" rel="noopener">Unpacking the Black Box: Benchmarking JS Parsing and Execution on Mobile Devices</a> (<a href="https://speakerdeck.com/desp/unpacking-the-black-box-benchmarking-js-parsing-and-execution-on-mobile-devices" target="_blank" rel="noopener">slides</a>)</li>
<li><a href="https://aerotwist.com/blog/when-everything-is-important-nothing-is/" target="_blank" rel="noopener">When everything’s important, nothing is!</a></li>
<li><a href="http://benediktmeurer.de/2016/12/16/the-truth-about-traditional-javascript-benchmarks/" target="_blank" rel="noopener">The truth about traditional JavaScript benchmarks</a></li>
<li><a href="http://stackoverflow.com/questions/1096907/do-browsers-parse-javascript-on-every-page-load/" target="_blank" rel="noopener">Do Browsers Parse JavaScript On Every Page Load</a></li>
</ul>
<p><em>With thanks to V8 (Toon Verwaest, Camillo Bruni, Benedikt Meurer, Marja Hölttä, Seth Thompson), Nolan Lawson (MS Edge), Malte Ubl (AMP), Tim Kadlec (Synk), Gray Norton (Chrome DX), Paul Lewis, Matt Gaunt and Rob Wormald (Angular) and for their reviews of this article.</em></p>
<p><strong>Update:</strong> Thanks to some awesome members of the community, this article is now available in <a href="https://mp.weixin.qq.com/s?__biz=MzIwNjQwMzUwMQ==&amp;mid=2247484987&amp;idx=1&amp;sn=7f20da20bc6baed62ca8ff115209942b&amp;chksm=972364f9a054edefccebc89bb4b39150328f84fc6a3da53dafa9563df7375fef00b3a1a4c483&amp;mpshare=1" target="_blank" rel="noopener">Chinese</a> and <a href="https://habrahabr.ru/company/mailru/blog/321748/" target="_blank" rel="noopener">Russian</a> too.</p>
<span>Source: </span><a href="https://medium.com/reloading/javascript-start-up-performance-69200f43b201" target="_blank" title="https://medium.com/reloading/javascript-start-up-performance-69200f43b201" class="post-from">https://medium.com/reloading/javascript-start-up-performance-69200f43b201</a></div></div></article></div></section><div class="wrap"><footer><div class="paginator"><a href="/2017/12/Cai-thien-toc-do-Web-App-voi-Tinder.html" class="prev">NEXT</a><a href="/2017/12/Hieu-ro-ve-Regular-Expressions-RegEx-khong-kho-nhu-tuong-tuong.html" class="next">PREV</a></div><div class="copyright"><p>© 2017 - 2018 <a href="http://nthung2112.github.io">Hung Tan Nguyen</a>, unless otherwise noted.</p></div></footer></div><script async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-41935289-1",'auto');ga('send','pageview');</script><script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script><script src="/js/zoom.js"></script><script src="/js/insight.js"></script></body></html>